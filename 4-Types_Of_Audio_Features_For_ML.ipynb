{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: 3rd December 2022 :: @5:27pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why audio features?\n",
    "- Descriptors of sound\n",
    "- Different features capture different aspects of sound\n",
    "- We can use these features to build intelligent audio systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio Feature Categorization:\n",
    "\n",
    "- Level of abstraction\n",
    "    - Relevant to music mostly\n",
    "\n",
    "- Temporal scope\n",
    "\n",
    "- Music aspect\n",
    "    - Relevant to music mostly\n",
    "\n",
    "- Signal domain\n",
    "\n",
    "- ML approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level of abstraction\n",
    "- High-level (Musical constructs and stuff)\n",
    "    - Instrumentation, key, chords, melody, rhythm, tempo, lyrics, genre, mood\n",
    "- Mid-level\n",
    "    - Pitch, beat-related descriptors, note-onsets, fluctuation patterns, MFCC's\n",
    "- Low-level\n",
    "    - Amplitude envelope, energy, spectral centroid, spectral flux, zero-crossing rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporal Scope\n",
    "- Instantaneous (~50ms)\n",
    "  - Human threshold around 10ms\n",
    "- Segment-level (seconds)\n",
    "  - 'A bar'\n",
    "  - 'Musical Phrase'\n",
    "- Global\n",
    "  - Aggregate features from lower temporal resolution features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Music Aspects:\n",
    "- Beat\n",
    "  - Note onsets etc\n",
    "- Timbre\n",
    "- Pitch\n",
    "  - Key\n",
    "- Harmony\n",
    "  - Key\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signal Domain Feature Categorization:\n",
    "- Time domain (Extracted from a waveform representation graph)\n",
    "  - Amplitude envelope\n",
    "  - Root-mean square energy\n",
    "  - Zero crossing rate\n",
    "  - x = time\n",
    "  - y = magnitude\n",
    "  - ...\n",
    "- Frequency Domain (Take raw audio from time domain and apply a Fourier transform)\n",
    "  - Band energy ratio\n",
    "  - Spectral centroid\n",
    "  - Spectral flux\n",
    "  - x = freq\n",
    "  - y = magnitude\n",
    "\n",
    "The issue is we don't have both of these things together.\n",
    "\n",
    "We have time-frequency domain features such as\n",
    "- Spectrogram\n",
    "  - Apply STFT (Short-time-fourier-transform) to get it.\n",
    "  - Shows amount of contribution of each frequency band at each frequency in time (brighter the colour the more contribution.)\n",
    "  - Y = Freq\n",
    "  - X = Time\n",
    "- Mel-spectrogram\n",
    "- Constant-Q transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Approach to feature classification\n",
    "- Traditional machine learning (features)\n",
    "    - Amplitude envelope\n",
    "    - Root-mean square energy\n",
    "    - Zero crossing energy\n",
    "    - Band energy ratio\n",
    "    - Spectral centroid\n",
    "    - Spectral flux\n",
    "    - Spectral spread\n",
    "    - Spectral roll-off\n",
    "- Deep Learning\n",
    "    - Unstructured data (Raw spectrogram etc)\n",
    "        - Raw audio in whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of Intelligent Audio Systems:\n",
    "- Classically we used\n",
    "    - DSP -> Rule-based systems (if else)\n",
    "- Traditional ML -> Feature engineering\n",
    "- Deep learning -> automatic feature extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
