{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: 3rd December 2022 :: @4:32pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio Signal:\n",
    "\n",
    "- A representation of sound.\n",
    "\n",
    "- Encodes all information we need to reproduce sound.\n",
    "\n",
    "- Huge problem -> Sound is a mechanical wave that is analog in nature and we wish to convert it to digital.\n",
    "\n",
    "\n",
    "Analog Signal (Problems for converting to digital):\n",
    "\n",
    "- Continous values for time.\n",
    "- Continous values for amplitude.\n",
    "- Issue of storage in digital format based on the value of cutting off the resolution that is sampled from time and amplitude.\n",
    "\n",
    "\n",
    "Digital Signal:\n",
    "- Sequence of discrete values.\n",
    "- Data points can only take on a finite number of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADC (Analog to Digital Conversion) There are 2 main steps...\n",
    "- Sampling\n",
    "    - Taking data points at a certain time interval periodically from a sinusodial wave. \n",
    "    - We decide on a sampling period and sample at equidistant intervals in time $T$\n",
    "    - Locating samples on time = $t_n = n \\times T$ where t = time, n = sample we want to find\n",
    "    - Sampling rate:\n",
    "        - $s_r = \\frac{1}{T}$\n",
    "        - Indicates the number of samples per second indicated in Hertz.\n",
    "        - Higher rate = bigger area under amplitude curve (sampling error)\n",
    "    - Why do we use 44100Hz in CD's?\n",
    "        - Nyquist Frequency: $f_N = \\frac{s_r}{2}$\n",
    "        - It is the upper bound in a digital signal which will not recreate any artifacts.\n",
    "        - Eg. $f_N = \\frac{44100Hz}{2} = 22050Hz$ this makes sense as the upper hearing range for a human is around 20,000Hz\n",
    "        - This means we can 'appreciate' the whole hearing range in a CD without artifacts.\n",
    "    - What are those artifacts?\n",
    "        - They are frequencies determined by aliasing.\n",
    "        - ![](ALIASING.png)\n",
    "        - The reconstructed signal in blue is aliasing and results in shifting down the real frequencies.\n",
    "\n",
    "- Quantization\n",
    "    - Quantizing on the amplitude is an idea of a discrete number of amplitude values and at each sample we affix the value to the closest Y-Axis value.\n",
    "    - This as comparison to sampling; produced a quantization error the same as the sampling error.\n",
    "    - Calculated in number of bits.\n",
    "    - The 'bit depth' = resolution of the quantization. CD = 16 bits, 'High Res' = 24 -> 32 -> 48.\n",
    "    - $2^16 = 65536$ values.\n",
    "\n",
    "- Memory needed to store 1's of sound:\n",
    "    - Formula in megabytes = $(((16bits \\times 44,100Hz) / 1,048,576 megabits/sec) / 8 bytes) \\times 60 seconds = 5.49 MB$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Pulse-Code Modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Range\n",
    "- Difference between largest / smallest signal in a recording.\n",
    "    - The higher the resolution the higher usually the dynamic range\n",
    "- Signal-to-quantization-noise ratio\n",
    "    - Relationship between max signal strength and quantization error\n",
    "    - Correlates with dynamic range.\n",
    "    - $SQNR \\approx 6.02 \\times Q$ where Q = bit depth\n",
    "        - For 16 bit depth $SQNR(16) \\approx 96dB$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we record sound?\n",
    "- Mechanical wave hits microphone capsule that vibrates slightly (it oscillates) this creates an analog electrical signal -> Then goes to a sound card (ADC) that samples and quantizes and anti-aliases with a low pass filter etc -> We get a digital signal that we store.\n",
    "\n",
    "Reproduction?\n",
    "- Laptop -> DAC conversion which creates an electrical signal which stimulates a membrane in a speaker to a speaker which makes a mechanical wave which hits our ear and creates a sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
